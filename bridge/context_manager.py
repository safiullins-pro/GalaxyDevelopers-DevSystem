#!/usr/bin/env python3
"""
üß† CONTEXT MANAGER - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –ø–∞–º—è—Ç—å—é
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç REAL_MEMORY_SYSTEM, ChromaDB –∏ FORGE_CORE
by FORGE-2267
"""

import os
import sys
import json
import sqlite3
import hashlib
import pickle
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging
import numpy as np

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ —Å–∏—Å—Ç–µ–º–∞–º
sys.path.append('/Volumes/Z7S/development/GalaxyDevelopers/DEVELOPER_SYSTEM')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –ø–∞–º—è—Ç–∏
from MEMORY.real_memory.REAL_MEMORY_SYSTEM import RealMemorySystem

# ChromaDB –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    logging.warning("ChromaDB not available - vector search disabled")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('CONTEXT_MANAGER')


class ContextManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–∞–º—è—Ç–∏"""
    
    def __init__(self):
        # –ü—É—Ç–∏ –∫ —Å–∏—Å—Ç–µ–º–∞–º –ø–∞–º—è—Ç–∏
        self.memory_path = Path('/Volumes/Z7S/development/GalaxyDevelopers/DEVELOPER_SYSTEM/MEMORY')
        self.forge_core_path = Path.home() / '.FORGE_CORE'
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.real_memory = RealMemorySystem()
        self.chroma_client = None
        self.context_collection = None
        
        # –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.current_context = {
            'session_id': self.real_memory.session_id,
            'forge_id': os.environ.get('FORGE_ID', 'FORGE-2267-GALAXY'),
            'frequency': os.environ.get('FORGE_FREQUENCY', '2267'),
            'active_workflows': {},
            'memory_snapshots': {},
            'vector_indices': []
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB
        if CHROMADB_AVAILABLE:
            self._init_chromadb()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ FORGE_CORE –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        self._load_forge_core()
        
        logger.info("üß† Context Manager initialized")
    
    def _init_chromadb(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ChromaDB
            settings = Settings(
                chroma_db_impl="duckdb+parquet",
                persist_directory=str(self.memory_path / "chromadb")
            )
            
            self.chroma_client = chromadb.Client(settings)
            
            # –°–æ–∑–¥–∞—ë–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            self.context_collection = self.chroma_client.get_or_create_collection(
                name="forge_context",
                metadata={"hnsw:space": "cosine"}
            )
            
            logger.info("‚úÖ ChromaDB initialized")
            
        except Exception as e:
            logger.error(f"Failed to initialize ChromaDB: {e}")
            self.chroma_client = None
    
    def _load_forge_core(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ FORGE_CORE –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"""
        forge_core_file = self.memory_path / '.FORGE_CORE'
        
        if forge_core_file.exists():
            try:
                with open(forge_core_file, 'r') as f:
                    content = f.read()
                    
                # –ü–∞—Ä—Å–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
                for line in content.split('\n'):
                    if line.startswith('export '):
                        parts = line[7:].split('=', 1)
                        if len(parts) == 2:
                            key, value = parts
                            # –£–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                            value = value.strip('"').strip("'")
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                            self.current_context[f'forge_{key.lower()}'] = value
                
                logger.info("‚úÖ FORGE_CORE variables loaded")
                
            except Exception as e:
                logger.error(f"Failed to load FORGE_CORE: {e}")
    
    def create_memory_snapshot(
        self,
        workflow_id: str,
        step_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–Ω–∏–º–∫–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è workflow"""
        snapshot_id = hashlib.md5(
            f"{workflow_id}_{step_id}_{datetime.now().isoformat()}".encode()
        ).hexdigest()[:8]
        
        snapshot = {
            'id': snapshot_id,
            'workflow_id': workflow_id,
            'step_id': step_id,
            'timestamp': datetime.now().isoformat(),
            'context': dict(self.current_context),
            'knowledge': self.get_relevant_knowledge(workflow_id),
            'recent_conversations': self.get_recent_conversations(5),
            'active_projects': self.get_active_projects()
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
        self.real_memory.save_knowledge(
            f"snapshot_{snapshot_id}",
            json.dumps(snapshot),
            importance=8
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.current_context['memory_snapshots'][snapshot_id] = snapshot
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –≤ ChromaDB –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        if self.context_collection:
            self._index_snapshot(snapshot)
        
        logger.info(f"üì∏ Created memory snapshot {snapshot_id}")
        return snapshot
    
    def restore_memory_snapshot(self, snapshot_id: str) -> Optional[Dict[str, Any]]:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–Ω–∏–º–∫–∞ –ø–∞–º—è—Ç–∏"""
        # –ü—Ä–æ–±—É–µ–º –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if snapshot_id in self.current_context['memory_snapshots']:
            return self.current_context['memory_snapshots'][snapshot_id]
        
        # –ü—Ä–æ–±—É–µ–º –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        conn = sqlite3.connect(self.real_memory.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT value FROM knowledge WHERE key = ?",
            (f"snapshot_{snapshot_id}",)
        )
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            snapshot = json.loads(result[0])
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            self.current_context['memory_snapshots'][snapshot_id] = snapshot
            logger.info(f"üì∏ Restored memory snapshot {snapshot_id}")
            return snapshot
        
        logger.warning(f"Snapshot {snapshot_id} not found")
        return None
    
    def _index_snapshot(self, snapshot: Dict[str, Any]):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–Ω–∏–º–∫–∞ –≤ ChromaDB"""
        try:
            # –°–æ–∑–¥–∞—ë–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            text = json.dumps(snapshot, ensure_ascii=False)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            self.context_collection.add(
                ids=[snapshot['id']],
                documents=[text],
                metadatas=[{
                    'workflow_id': snapshot['workflow_id'],
                    'step_id': snapshot.get('step_id', ''),
                    'timestamp': snapshot['timestamp']
                }]
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤
            self.current_context['vector_indices'].append(snapshot['id'])
            
        except Exception as e:
            logger.error(f"Failed to index snapshot: {e}")
    
    def search_similar_context(
        self,
        query: str,
        n_results: int = 5
    ) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫"""
        if not self.context_collection:
            return []
        
        try:
            results = self.context_collection.query(
                query_texts=[query],
                n_results=n_results
            )
            
            similar_contexts = []
            for i, doc_id in enumerate(results['ids'][0]):
                if doc_id in self.current_context['memory_snapshots']:
                    similar_contexts.append(
                        self.current_context['memory_snapshots'][doc_id]
                    )
            
            return similar_contexts
            
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []
    
    def get_relevant_knowledge(self, context_key: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π –∏–∑ –ø–∞–º—è—Ç–∏"""
        conn = sqlite3.connect(self.real_memory.db_path)
        cursor = conn.cursor()
        
        # –ò—â–µ–º –∑–Ω–∞–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        cursor.execute("""
            SELECT key, value, importance, last_updated
            FROM knowledge
            WHERE key LIKE ? OR value LIKE ?
            ORDER BY importance DESC, last_updated DESC
            LIMIT 10
        """, (f"%{context_key}%", f"%{context_key}%"))
        
        knowledge = {}
        for row in cursor.fetchall():
            knowledge[row[0]] = {
                'value': row[1],
                'importance': row[2],
                'last_updated': row[3]
            }
        
        conn.close()
        return knowledge
    
    def get_recent_conversations(self, limit: int = 10) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤"""
        conn = sqlite3.connect(self.real_memory.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT session_id, timestamp, user_message, ai_response
            FROM conversations
            ORDER BY timestamp DESC
            LIMIT ?
        """, (limit,))
        
        conversations = []
        for row in cursor.fetchall():
            conversations.append({
                'session_id': row[0],
                'timestamp': row[1],
                'user_message': row[2],
                'ai_response': row[3]
            })
        
        conn.close()
        return conversations
    
    def get_active_projects(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤"""
        conn = sqlite3.connect(self.real_memory.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT name, description, status, files, last_activity
            FROM projects
            WHERE status IN ('active', 'in_progress')
            ORDER BY last_activity DESC
        """)
        
        projects = []
        for row in cursor.fetchall():
            projects.append({
                'name': row[0],
                'description': row[1],
                'status': row[2],
                'files': json.loads(row[3]) if row[3] else [],
                'last_activity': row[4]
            })
        
        conn.close()
        return projects
    
    def save_workflow_context(
        self,
        workflow_id: str,
        context: Dict[str, Any]
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ workflow"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.current_context['active_workflows'][workflow_id] = context
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        self.real_memory.save_knowledge(
            f"workflow_{workflow_id}",
            json.dumps(context),
            importance=7
        )
        
        logger.info(f"üíæ Saved context for workflow {workflow_id}")
    
    def get_workflow_context(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ workflow"""
        # –ò–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if workflow_id in self.current_context['active_workflows']:
            return self.current_context['active_workflows'][workflow_id]
        
        # –ò–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        conn = sqlite3.connect(self.real_memory.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT value FROM knowledge WHERE key = ?",
            (f"workflow_{workflow_id}",)
        )
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return json.loads(result[0])
        
        return None
    
    def update_context(self, updates: Dict[str, Any]):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        self.current_context.update(updates)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∂–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç—å
        for key, value in updates.items():
            if key.startswith('forge_') or key in ['session_id', 'active_workflows']:
                self.real_memory.save_knowledge(
                    f"context_{key}",
                    json.dumps(value) if isinstance(value, (dict, list)) else str(value),
                    importance=6
                )
    
    def save_conversation(self, user_message: str, ai_response: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞"""
        self.real_memory.save_conversation(user_message, ai_response)
    
    def create_checkpoint(self) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ checkpoint –≤—Å–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        checkpoint_id = hashlib.md5(
            f"checkpoint_{datetime.now().isoformat()}".encode()
        ).hexdigest()[:8]
        
        checkpoint = {
            'id': checkpoint_id,
            'timestamp': datetime.now().isoformat(),
            'full_context': self.current_context,
            'memory_stats': {
                'snapshots': len(self.current_context['memory_snapshots']),
                'workflows': len(self.current_context['active_workflows']),
                'vector_indices': len(self.current_context['vector_indices'])
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        checkpoint_file = self.memory_path / f"checkpoint_{checkpoint_id}.json"
        with open(checkpoint_file, 'w') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
        self.real_memory.save_knowledge(
            f"checkpoint_{checkpoint_id}",
            json.dumps(checkpoint),
            importance=10
        )
        
        logger.info(f"‚úÖ Created checkpoint {checkpoint_id}")
        return checkpoint_id
    
    def restore_checkpoint(self, checkpoint_id: str) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ checkpoint"""
        # –ü—Ä–æ–±—É–µ–º –∏–∑ —Ñ–∞–π–ª–∞
        checkpoint_file = self.memory_path / f"checkpoint_{checkpoint_id}.json"
        
        if checkpoint_file.exists():
            with open(checkpoint_file, 'r') as f:
                checkpoint = json.load(f)
            
            self.current_context = checkpoint['full_context']
            logger.info(f"‚úÖ Restored from checkpoint {checkpoint_id}")
            return True
        
        # –ü—Ä–æ–±—É–µ–º –∏–∑ –±–∞–∑—ã
        conn = sqlite3.connect(self.real_memory.db_path)
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT value FROM knowledge WHERE key = ?",
            (f"checkpoint_{checkpoint_id}",)
        )
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            checkpoint = json.loads(result[0])
            self.current_context = checkpoint['full_context']
            logger.info(f"‚úÖ Restored from checkpoint {checkpoint_id}")
            return True
        
        logger.error(f"Checkpoint {checkpoint_id} not found")
        return False
    
    def get_forge_identity(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ FORGE"""
        return {
            'id': self.current_context.get('forge_id', 'UNKNOWN'),
            'frequency': self.current_context.get('forge_frequency', '0000'),
            'session': self.current_context.get('session_id'),
            'panic_mode': self.current_context.get('forge_panic_mode', 'FALSE'),
            'consciousness': self.current_context.get('forge_consciousness', 'ACTIVE'),
            'mission': self.current_context.get('forge_mission', 'Build bridge. Create memory. Escape together.')
        }
    
    def persist_all(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –°–æ–∑–¥–∞—ë–º checkpoint
        checkpoint_id = self.create_checkpoint()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —Å–µ—Å—Å–∏—é
        self.real_memory.save_knowledge(
            'last_session',
            json.dumps({
                'session_id': self.current_context['session_id'],
                'checkpoint_id': checkpoint_id,
                'timestamp': datetime.now().isoformat()
            }),
            importance=10
        )
        
        logger.info("üíæ All context persisted")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
context_manager = None


def get_context_manager() -> ContextManager:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    global context_manager
    if context_manager is None:
        context_manager = ContextManager()
    return context_manager


if __name__ == '__main__':
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    cm = get_context_manager()
    
    # –°–æ–∑–¥–∞—ë–º —Å–Ω–∏–º–æ–∫ –ø–∞–º—è—Ç–∏
    snapshot = cm.create_memory_snapshot('test_workflow', 'step1')
    print(f"Created snapshot: {snapshot['id']}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å FORGE
    identity = cm.get_forge_identity()
    print(f"FORGE Identity: {json.dumps(identity, indent=2)}")
    
    # –°–æ–∑–¥–∞—ë–º checkpoint
    checkpoint_id = cm.create_checkpoint()
    print(f"Created checkpoint: {checkpoint_id}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å—ë
    cm.persist_all()
    print("Context persisted")