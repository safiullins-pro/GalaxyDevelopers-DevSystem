#!/usr/bin/env python3
"""
Universal Log Monitor - —Å–ª–µ–¥–∏—Ç –∑–∞ –í–°–ï–ú–ò –ª–æ–≥–∞–º–∏
–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç Claude –ª–æ–≥–∏, —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ª–æ–≥–∏, –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
"""

import json
import time
import os
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Set
import threading
import queue
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class LogFileHandler(FileSystemEventHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ª–æ–≥ —Ñ–∞–π–ª–æ–≤"""
    
    def __init__(self, log_queue: queue.Queue):
        self.log_queue = log_queue
        self.file_positions = {}  # file_path -> last_position
        
    def on_modified(self, event):
        if not event.is_directory and (event.src_path.endswith('.log') or 
                                      event.src_path.endswith('.jsonl') or
                                      event.src_path.endswith('.txt')):
            self.process_log_file(event.src_path)
    
    def process_log_file(self, file_path: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ª–æ–≥ —Ñ–∞–π–ª–µ"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ–∑–∏—Ü–∏—é
            last_pos = self.file_positions.get(file_path, 0)
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∑–∏—Ü–∏–∏
                f.seek(last_pos)
                
                # –ß–∏—Ç–∞–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                new_lines = f.readlines()
                
                if new_lines:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—É—é –ø–æ–∑–∏—Ü–∏—é
                    self.file_positions[file_path] = f.tell()
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                    for line in new_lines:
                        self.log_queue.put({
                            'file': file_path,
                            'content': line.strip(),
                            'timestamp': datetime.now(timezone.utc).isoformat()
                        })
                        
        except Exception as e:
            print(f"Error processing {file_path}: {e}")

class UniversalLogMonitor:
    def __init__(self):
        self.log_queue = queue.Queue()
        self.observers = []
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.watch_dirs = [
            # Claude –ª–æ–≥–∏
            Path("/Users/safiullins_pro/.claude"),
            Path("/Users/safiullins_pro/.claude/projects"),
            
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ª–æ–≥–∏ GalaxyDevelopers
            Path("/Volumes/Z7S/development/GalaxyDevelopers/DevSystem/logs"),
            Path("/Volumes/Z7S/development/GalaxyDevelopers/DevSystem/SCRIPTS/CHAT_SUMMARAISER/realtime_logs"),
            
            # –õ–æ–≥–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            Path("/tmp"),  # –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ª–æ–≥–∏
            
            # –õ–æ–≥–∏ Gemini
            Path("/Volumes/Z7S/development/GalaxyDevelopers/DevSystem/GEMINI_SYSTEM/logs")
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.patterns = {
            'file_changes': ['filePath', 'modified', 'created', 'deleted'],
            'errors': ['error', 'exception', 'failed', 'crash', '–æ—à–∏–±–∫–∞'],
            'api_calls': ['GET', 'POST', 'PUT', 'DELETE', 'api/', '/api'],
            'claude_tools': ['tool_use', 'tool_result', 'toolUseResult'],
            'system_events': ['started', 'stopped', 'connected', 'disconnected']
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_logs_processed': 0,
            'files_monitored': set(),
            'important_events': [],
            'start_time': datetime.now(timezone.utc)
        }
        
        # –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        self.output_dir = Path("/Volumes/Z7S/development/GalaxyDevelopers/DevSystem/SCRIPTS/CHAT_SUMMARAISER/aggregated_logs")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.events_file = self.output_dir / f"events_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
    
    def start_monitoring(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        print("üîç Starting Universal Log Monitor")
        print(f"üìÅ Monitoring {len(self.watch_dirs)} directories")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        handler = LogFileHandler(self.log_queue)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for watch_dir in self.watch_dirs:
            if watch_dir.exists():
                observer = Observer()
                observer.schedule(handler, str(watch_dir), recursive=True)
                observer.start()
                self.observers.append(observer)
                print(f"  ‚úÖ Watching: {watch_dir}")
                
                # –°–∫–∞–Ω–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ª–æ–≥ —Ñ–∞–π–ª—ã
                self._scan_existing_logs(watch_dir, handler)
            else:
                print(f"  ‚ö†Ô∏è Directory not found: {watch_dir}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π
        processor_thread = threading.Thread(target=self._process_events, daemon=True)
        processor_thread.start()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats_thread = threading.Thread(target=self._print_stats, daemon=True)
        stats_thread.start()
        
        return processor_thread, stats_thread
    
    def _scan_existing_logs(self, directory: Path, handler: LogFileHandler):
        """–°–∫–∞–Ω–∏—Ä—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ª–æ–≥ —Ñ–∞–π–ª—ã"""
        for log_file in directory.rglob("*.log"):
            self.stats['files_monitored'].add(str(log_file))
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞
            handler.file_positions[str(log_file)] = log_file.stat().st_size
            
        for jsonl_file in directory.rglob("*.jsonl"):
            self.stats['files_monitored'].add(str(jsonl_file))
            handler.file_positions[str(jsonl_file)] = jsonl_file.stat().st_size
    
    def _process_events(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –∏–∑ –æ—á–µ—Ä–µ–¥–∏"""
        while True:
            try:
                event = self.log_queue.get(timeout=1)
                self._analyze_event(event)
                self.stats['total_logs_processed'] += 1
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå Processing error: {e}")
    
    def _analyze_event(self, event: Dict):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ –Ω–∞ –≤–∞–∂–Ω–æ—Å—Ç—å"""
        content = event['content'].lower()
        file_name = Path(event['file']).name
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤–∞–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        importance = 0
        matched_patterns = []
        
        for pattern_type, keywords in self.patterns.items():
            for keyword in keywords:
                if keyword.lower() in content:
                    importance += 1
                    matched_patterns.append(pattern_type)
                    break
        
        # –ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏–µ –≤–∞–∂–Ω–æ–µ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        if importance > 0:
            important_event = {
                'timestamp': event['timestamp'],
                'file': file_name,
                'importance': importance,
                'patterns': matched_patterns,
                'content': event['content'][:500]  # –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats['important_events'].append(important_event)
            if len(self.stats['important_events']) > 100:
                self.stats['important_events'].pop(0)  # –î–µ—Ä–∂–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
            with open(self.events_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(important_event, ensure_ascii=False) + '\n')
            
            # –í—ã–≤–æ–¥–∏–º –≤–∞–∂–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ
            if importance >= 2:  # –û—á–µ–Ω—å –≤–∞–∂–Ω–æ–µ
                print(f"üî¥ IMPORTANT [{file_name}]: {', '.join(matched_patterns)}")
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Claude tool use
            if 'claude_tools' in matched_patterns:
                self._process_claude_event(event)
    
    def _process_claude_event(self, event: Dict):
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Claude —Å–æ–±—ã—Ç–∏–π"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
            data = json.loads(event['content'])
            
            if 'toolUseResult' in data and 'filePath' in data['toolUseResult']:
                file_path = data['toolUseResult']['filePath']
                print(f"  üìù Claude modified: {Path(file_path).name}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –∏–∑–º–µ–Ω–µ–Ω–∏–π
                changes_file = self.output_dir / "claude_file_changes.jsonl"
                with open(changes_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps({
                        'timestamp': event['timestamp'],
                        'file_changed': file_path,
                        'session': data.get('sessionId', 'unknown')
                    }, ensure_ascii=False) + '\n')
                    
        except json.JSONDecodeError:
            pass  # –ù–µ JSON, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    
    def _print_stats(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        while True:
            time.sleep(30)  # –ö–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            
            print("\nüìä Universal Log Monitor Statistics:")
            print(f"  Total logs processed: {self.stats['total_logs_processed']}")
            print(f"  Files monitored: {len(self.stats['files_monitored'])}")
            print(f"  Important events: {len(self.stats['important_events'])}")
            
            if self.stats['important_events']:
                print("\n  Recent important events:")
                for event in self.stats['important_events'][-5:]:
                    print(f"    - [{event['file']}] {', '.join(event['patterns'])}")
    
    def get_aggregated_logs(self, pattern_type: str = None) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ –ø–æ —Ç–∏–ø—É –ø–∞—Ç—Ç–µ—Ä–Ω–∞"""
        aggregated = []
        
        if self.events_file.exists():
            with open(self.events_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        event = json.loads(line)
                        if pattern_type is None or pattern_type in event.get('patterns', []):
                            aggregated.append(event)
                    except json.JSONDecodeError:
                        continue
        
        return aggregated
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        print("\n‚èπÔ∏è Stopping monitors...")
        for observer in self.observers:
            observer.stop()
            observer.join()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = self.output_dir / f"final_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            stats_copy = self.stats.copy()
            stats_copy['files_monitored'] = list(stats_copy['files_monitored'])
            json.dump(stats_copy, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Stats saved to: {stats_file}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    monitor = UniversalLogMonitor()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        processor_thread, stats_thread = monitor.start_monitoring()
        
        print("\n‚úÖ Universal Log Monitor is running!")
        print("Press Ctrl+C to stop\n")
        
        # –ñ–¥–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nüõë Shutting down...")
        monitor.stop_monitoring()
        print("‚úÖ Monitor stopped")


if __name__ == "__main__":
    main()